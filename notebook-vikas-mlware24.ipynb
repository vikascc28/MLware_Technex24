# %% [code] {"execution":{"iopub.status.busy":"2024-03-17T01:51:29.315408Z","iopub.execute_input":"2024-03-17T01:51:29.315775Z","iopub.status.idle":"2024-03-17T01:51:29.322187Z","shell.execute_reply.started":"2024-03-17T01:51:29.315744Z","shell.execute_reply":"2024-03-17T01:51:29.321108Z"}}
import os
import re
import numpy as np
import pandas as pd
from PIL import Image
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, TimeDistributed, Reshape
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import joblib

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:18:00.108011Z","iopub.execute_input":"2024-03-16T19:18:00.108522Z","iopub.status.idle":"2024-03-16T19:18:00.158628Z","shell.execute_reply.started":"2024-03-16T19:18:00.108495Z","shell.execute_reply":"2024-03-16T19:18:00.157607Z"}}
train_labels=pd.read_csv("/kaggle/input/mlware24/train-labels_mlware.csv")

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:18:00.159959Z","iopub.execute_input":"2024-03-16T19:18:00.160797Z","iopub.status.idle":"2024-03-16T19:18:00.186468Z","shell.execute_reply.started":"2024-03-16T19:18:00.160754Z","shell.execute_reply":"2024-03-16T19:18:00.185517Z"}}
train_labels.shape

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:18:00.189120Z","iopub.execute_input":"2024-03-16T19:18:00.189479Z","iopub.status.idle":"2024-03-16T19:18:00.226830Z","shell.execute_reply.started":"2024-03-16T19:18:00.189448Z","shell.execute_reply":"2024-03-16T19:18:00.225892Z"}}
train_labels.info()

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:18:00.227971Z","iopub.execute_input":"2024-03-16T19:18:00.228314Z","iopub.status.idle":"2024-03-16T19:18:00.242969Z","shell.execute_reply.started":"2024-03-16T19:18:00.228281Z","shell.execute_reply":"2024-03-16T19:18:00.242035Z"}}
train_labels.head()

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:18:00.244328Z","iopub.execute_input":"2024-03-16T19:18:00.245003Z","iopub.status.idle":"2024-03-16T19:18:00.259622Z","shell.execute_reply.started":"2024-03-16T19:18:00.244965Z","shell.execute_reply":"2024-03-16T19:18:00.258596Z"}}
train_labels.drop("Unnamed: 0",axis=1)

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:18:00.260832Z","iopub.execute_input":"2024-03-16T19:18:00.261184Z","iopub.status.idle":"2024-03-16T19:18:00.267275Z","shell.execute_reply.started":"2024-03-16T19:18:00.261148Z","shell.execute_reply":"2024-03-16T19:18:00.266435Z"}}
def load_image(img_path):
    return Image.open(img_path)

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:18:00.268609Z","iopub.execute_input":"2024-03-16T19:18:00.269389Z","iopub.status.idle":"2024-03-16T19:20:27.980277Z","shell.execute_reply.started":"2024-03-16T19:18:00.269354Z","shell.execute_reply":"2024-03-16T19:20:27.979326Z"}}
data = {}
for index, row in train_labels.iterrows():
    # Get the image ID and label
    image_id = row['image']
    label = row['text']

    # Load the image
    images = load_image(f'/kaggle/input/mlware24/train_images_mlware/train_images/{image_id}')

    # Store the image and label in the dictionary
    data[image_id] = {'image': images, 'label': label}

# Print the first 5 items in the dictionary to verify the data
for key in list(data.keys())[:5]:
    print(key, data[key]['label'])

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:20:27.981491Z","iopub.execute_input":"2024-03-16T19:20:27.981796Z","iopub.status.idle":"2024-03-16T19:20:29.633841Z","shell.execute_reply.started":"2024-03-16T19:20:27.981770Z","shell.execute_reply":"2024-03-16T19:20:29.632901Z"}}


# Specify the directory where the images are
image_dir = '/kaggle/input/mlware24/train_images_mlware/train_images/'

# Get the list of image file names
image_files = os.listdir(image_dir)

# Sort the image files
image_files.sort()

# Display the first 5 images
for i in range(5):
    # Open the image file
    image = Image.open(os.path.join(image_dir, image_files[i]))
    
    # Display the image
    plt.imshow(image)
    plt.title(image_files[i])
    plt.show()


# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:20:29.637506Z","iopub.execute_input":"2024-03-16T19:20:29.637788Z","iopub.status.idle":"2024-03-16T19:20:29.642558Z","shell.execute_reply.started":"2024-03-16T19:20:29.637764Z","shell.execute_reply":"2024-03-16T19:20:29.641502Z"}}
import numpy as np
from keras.preprocessing.image import img_to_array
from keras.utils import to_categorical
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:20:29.643618Z","iopub.execute_input":"2024-03-16T19:20:29.643907Z","iopub.status.idle":"2024-03-16T19:20:52.044856Z","shell.execute_reply.started":"2024-03-16T19:20:29.643884Z","shell.execute_reply":"2024-03-16T19:20:52.043971Z"}}
X = np.array([img_to_array(data[key]['image'].convert('L').resize((50, 50))) for key in data.keys()])
X = X.astype('float32') / 255

# Encode labels using one-hot encoding
lb = LabelBinarizer().fit(list(data[key]['label'] for key in data.keys()))
y = lb.transform(list(data[key]['label'] for key in data.keys()))

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:20:52.046257Z","iopub.execute_input":"2024-03-16T19:20:52.046996Z","iopub.status.idle":"2024-03-16T19:20:52.935381Z","shell.execute_reply.started":"2024-03-16T19:20:52.046957Z","shell.execute_reply":"2024-03-16T19:20:52.934599Z"}}
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Define the model
model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=(50, 50, 1), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(len(lb.classes_), activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])


# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:20:52.936607Z","iopub.execute_input":"2024-03-16T19:20:52.937057Z","iopub.status.idle":"2024-03-16T19:21:56.942621Z","shell.execute_reply.started":"2024-03-16T19:20:52.937019Z","shell.execute_reply":"2024-03-16T19:21:56.941606Z"}}
# Train the model
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:21:56.943753Z","iopub.execute_input":"2024-03-16T19:21:56.944039Z","iopub.status.idle":"2024-03-16T19:21:58.277698Z","shell.execute_reply.started":"2024-03-16T19:21:56.944015Z","shell.execute_reply":"2024-03-16T19:21:58.276383Z"}}
# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print('Test loss:', loss)
print('Test accuracy:', accuracy)

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:21:58.279136Z","iopub.execute_input":"2024-03-16T19:21:58.279518Z","iopub.status.idle":"2024-03-16T19:21:58.920674Z","shell.execute_reply.started":"2024-03-16T19:21:58.279484Z","shell.execute_reply":"2024-03-16T19:21:58.919746Z"}}
# Make a prediction for the first image in the test set
prediction = model.predict(np.array([X_test[0]]))

# The prediction is a one-hot encoded array, so we'll use the inverse_transform method to get the original label
predicted_label = lb.inverse_transform(prediction)

print('Predicted label:', predicted_label)
print('Actual label:', lb.inverse_transform(np.array([y_test[0]])))


# %% [markdown]
# **so this code did'nt worked properly will do some more changes in the images as it is a graysclae image need to do some augumentation**

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:21:58.922051Z","iopub.execute_input":"2024-03-16T19:21:58.922812Z","iopub.status.idle":"2024-03-16T19:22:06.666983Z","shell.execute_reply.started":"2024-03-16T19:21:58.922776Z","shell.execute_reply":"2024-03-16T19:22:06.666203Z"}}
# Convert images to grayscale and resize them
X = np.array([img_to_array(data[key]['image'].convert('L').resize((128, 128))) for key in data.keys()])
X = X.astype('float32') / 255

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:22:06.672261Z","iopub.execute_input":"2024-03-16T19:22:06.672544Z","iopub.status.idle":"2024-03-16T19:22:06.680236Z","shell.execute_reply.started":"2024-03-16T19:22:06.672520Z","shell.execute_reply":"2024-03-16T19:22:06.679301Z"}}
X[:2]

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:22:06.681598Z","iopub.execute_input":"2024-03-16T19:22:06.681955Z","iopub.status.idle":"2024-03-16T19:22:07.292644Z","shell.execute_reply.started":"2024-03-16T19:22:06.681930Z","shell.execute_reply":"2024-03-16T19:22:07.291831Z"}}
from tensorflow.keras.preprocessing.text import Tokenizer


# Flatten the array of labels
labels = [data[key]['label'] for key in data.keys()]

# Initialize the tokenizer
tokenizer = Tokenizer(char_level=True,lower=False)

# Fit the tokenizer on the labels
tokenizer.fit_on_texts(labels)

# Transform the labels to one-hot encoded vectors
y = np.array([tokenizer.texts_to_matrix(label) for label in labels])


# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:22:07.294326Z","iopub.execute_input":"2024-03-16T19:22:07.294578Z","iopub.status.idle":"2024-03-16T19:22:07.305392Z","shell.execute_reply.started":"2024-03-16T19:22:07.294557Z","shell.execute_reply":"2024-03-16T19:22:07.304410Z"}}
y[:2]

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:22:07.306609Z","iopub.execute_input":"2024-03-16T19:22:07.306964Z","iopub.status.idle":"2024-03-16T19:22:07.691956Z","shell.execute_reply.started":"2024-03-16T19:22:07.306926Z","shell.execute_reply":"2024-03-16T19:22:07.691109Z"}}
from keras.layers import LSTM, TimeDistributed, Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.models import Sequential

# Define the model

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)))  # Changed from (128, 128, 3) to (128, 128, 1)
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(1020, activation='relu'))
model.add(Reshape((6, -1)))  # Reshape the output into sequences
model.add(LSTM(128, return_sequences=True))
model.add(TimeDistributed(Dense(len(tokenizer.word_index) + 1, activation='softmax')))


# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:22:07.693070Z","iopub.execute_input":"2024-03-16T19:22:07.693325Z","iopub.status.idle":"2024-03-16T19:22:08.111697Z","shell.execute_reply.started":"2024-03-16T19:22:07.693303Z","shell.execute_reply":"2024-03-16T19:22:08.110899Z"}}
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:22:08.112866Z","iopub.execute_input":"2024-03-16T19:22:08.113155Z","iopub.status.idle":"2024-03-16T19:39:11.214056Z","shell.execute_reply.started":"2024-03-16T19:22:08.113124Z","shell.execute_reply":"2024-03-16T19:39:11.213156Z"}}
# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=32)

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:39:11.216555Z","iopub.execute_input":"2024-03-16T19:39:11.216876Z","iopub.status.idle":"2024-03-16T19:39:11.595872Z","shell.execute_reply.started":"2024-03-16T19:39:11.216849Z","shell.execute_reply":"2024-03-16T19:39:11.594989Z"}}
test_dir = '/kaggle/input/mlware24/test_images_mlware/test_images/'
test_files = os.listdir(test_dir)

# Initialize an empty list to store the extracted numbers
extracted_numbers = []

for file in test_files:
    # Use regex to find the numbers in the filename
    match = re.search(r'\d+', file)
    if match:
        number = match.group()
        # Remove leading zeros
        number = str(int(number))
        extracted_numbers.append(number)

extracted_numbers.sort()
print(extracted_numbers)

# %% [code] {"execution":{"iopub.status.busy":"2024-03-16T19:39:11.596924Z","iopub.execute_input":"2024-03-16T19:39:11.597243Z"}}
predictions = []

for file in test_files:
    image = Image.open(os.path.join(test_dir, file)).convert('L').resize((128, 128))
    
    image = img_to_array(image) / 255.0
    
    prediction = model.predict(np.expand_dims(image, axis=0))
    
    predicted_label = ''.join(tokenizer.sequences_to_texts(prediction.argmax(axis=-1))).replace(' ', '')

    predictions.append(predicted_label)


# %% [code]
# Specify the directory where the images are
image_dir = '/kaggle/input/mlware24/test_images_mlware/test_images/'

# Get the list of image file names
image_files = os.listdir(image_dir)

# Sort the image files
image_files.sort()

# Display the first 5 images
for i in range(5):
    # Open the image file
    image = Image.open(os.path.join(image_dir, image_files[i]))
    
    # Display the image
    plt.imshow(image)
    plt.title(image_files[i])
    plt.show()

# %% [code]
df = pd.DataFrame({
    'ID': extracted_numbers,
    'text': predictions
})

# Print the DataFrame
print(df)

# %% [code]
image = Image.open('/kaggle/input/mlware24/test_images_mlware/test_images/test-2144.png')

# Display the image
plt.imshow(image)
plt.show()

# %% [code]
df.to_csv('submission_file_mlware.csv', index=False)

# %% [code]
